{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPM91/n4e/uYm14D+B+vplv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mOnchhh/github-porfolio/blob/main/CSCI_111_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instructions**\n",
        "---\n",
        "This notebook is in completion of the Final Project for CSCI 111 - ST2. It contains the source code for a Machine Learning Output wherein the models attempts to predict **Banana Quality** through Logistic Regression and Random Forest Classification.\n",
        "\n",
        "In order to predict the banana sample's quality, the attribute **\"quality_category\"** has been used as the target attribute, or independent variable.\n",
        "\n",
        "Additionally, this notebook also includes a Random Forest Regressor model further below, which attempts to predict \"quality_score\" rather than \"quality_category.\"\n",
        "\n",
        "\n",
        "```\n",
        "To adjust which columns are included in the dataframe, look to the \"Data Preparation\"\n",
        "section and utilize the data.drop() function.\n",
        "\n",
        "To change the test sizes to be used in model testing, see the train_test_split()\n",
        "function at line 30, and change the argument \"test_size\" from 0.2 to whichever test\n",
        "size you prefer.\n",
        "```\n",
        "\n",
        "The sources used in the fulfillment of this requirement can be found at the bottom of this notebook."
      ],
      "metadata": {
        "id": "ZuQQ8HjowN7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Models: Logistic Regression & Random Forest Classification**"
      ],
      "metadata": {
        "id": "K0G3p63t8eUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "data = pd.read_csv(\"banana_quality_dataset.csv\")\n",
        "\n",
        "# ------------------------ Data Preparation ------------------------\n",
        "data.drop([\"region\", \"harvest_date\",\"quality_score\"], axis=1, inplace=True) # Upon including \"soil_nitrogen_ppm\" in the model training,\n",
        "                                                                            # there remains no difference in the classification scores\n",
        "                                                                            # during model evaluation.\n",
        "data[\"altitude_m\"] = pd.to_numeric(data[\"altitude_m\"], errors='coerce')\n",
        "data[\"rainfall_mm\"] = pd.to_numeric(data[\"rainfall_mm\"], errors='coerce')\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "data[\"quality_category\"] = data[\"quality_category\"].map({\"Unripe\": 0, \"Processing\": 1, \"Good\": 2, \"Premium\": 3})\n",
        "data[\"ripeness_category\"] = data[\"ripeness_category\"].map({\"Green\": 0, \"Turning\": 1, \"Ripe\": 2, \"Overripe\": 3})\n",
        "\n",
        "# Label Encode region\n",
        "le = LabelEncoder()\n",
        "data[\"variety\"] = le.fit_transform(data[\"variety\"])\n",
        "\n",
        "# ------------------------ Model Training ------------------------\n",
        "x = data.drop(\"quality_category\", axis=1)\n",
        "qc = data[\"quality_category\"]\n",
        "\n",
        "# Split and Standardize\n",
        "x_train, x_test, qc_train, qc_test = train_test_split(x, qc, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# Logistic Regression Model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(x_train, qc_train)\n",
        "\n",
        "# LR Model Evaluation\n",
        "qc_prediction_lr = lr_model.predict(x_test)\n",
        "print(\"[1] Logistic Regression\")\n",
        "print(\"confusion matrix:\\n\", confusion_matrix(qc_test, qc_prediction_lr),\"\\n\")\n",
        "print(\"classification report\\n\", classification_report(qc_test, qc_prediction_lr))\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(x_train, qc_train)\n",
        "\n",
        "# RF Model Evaluation\n",
        "qc_prediction_rf = rf_model.predict(x_test)\n",
        "print(\"\\n[2] Random Forest\")\n",
        "print(\"confusion Matrix:\\n\", confusion_matrix(qc_test, qc_prediction_rf))\n",
        "print(\"classification Report:\\n\", classification_report(qc_test, qc_prediction_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEGXy7MF7FBe",
        "outputId": "e73b6905-203e-4a0e-9dc3-1d33a75761cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] Logistic Regression\n",
            "confusion matrix:\n",
            " [[  4   4   0   0]\n",
            " [  0 100   0   0]\n",
            " [  0   8  81   0]\n",
            " [  0   0   1   2]] \n",
            "\n",
            "classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         8\n",
            "           1       0.89      1.00      0.94       100\n",
            "           2       0.99      0.91      0.95        89\n",
            "           3       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.97      0.77      0.84       200\n",
            "weighted avg       0.94      0.94      0.93       200\n",
            "\n",
            "\n",
            "[2] Random Forest\n",
            "confusion Matrix:\n",
            " [[ 2  6  0  0]\n",
            " [ 0 99  1  0]\n",
            " [ 0 16 73  0]\n",
            " [ 0  0  1  2]]\n",
            "classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.25      0.40         8\n",
            "           1       0.82      0.99      0.90       100\n",
            "           2       0.97      0.82      0.89        89\n",
            "           3       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.88       200\n",
            "   macro avg       0.95      0.68      0.75       200\n",
            "weighted avg       0.90      0.88      0.87       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Regression**"
      ],
      "metadata": {
        "id": "b4dGXJLOIB5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilises Random Forest Regression in order to predict **\"quality_score\"** rather than **\"quality_category.\"**"
      ],
      "metadata": {
        "id": "DyrUKOW2rbOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"banana_quality_dataset.csv\")\n",
        "\n",
        "# Data Preparation\n",
        "data.drop([\"region\", \"harvest_date\", \"quality_category\"], axis=1, inplace=True)\n",
        "data[\"altitude_m\"] = pd.to_numeric(data[\"altitude_m\"], errors='coerce')\n",
        "data[\"rainfall_mm\"] = pd.to_numeric(data[\"rainfall_mm\"], errors='coerce')\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "data[\"ripeness_category\"] = data[\"ripeness_category\"].map({\"Green\": 0, \"Turning\": 1, \"Ripe\": 2, \"Overripe\": 3})\n",
        "\n",
        "# Encode variety using LabelEncoder\n",
        "le = LabelEncoder()\n",
        "data[\"variety\"] = le.fit_transform(data[\"variety\"])\n",
        "\n",
        "# Target attribute\n",
        "X = data.drop(columns=[\"quality_score\"])\n",
        "y = data[\"quality_score\"]\n",
        "\n",
        "# Split and Standardize\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "print(\"[3] Random Forest Regressor\")\n",
        "print(\"MSE :\", mean_squared_error(y_test, y_pred))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAmxxKnuxjnH",
        "outputId": "21dbac69-b02b-4935-e07d-d1ec757c6a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3] Random Forest Regressor\n",
            "MSE : 0.013102816650000015\n",
            "RMSE: 0.11446753535391603\n",
            "R² Score: 0.9564760693424342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **References**\n",
        "\n",
        "Machine Learning Logistic Regression Model. Retrieved from https://github.com/FullStackWithLawrence/006-scikit-learn-logistic-regression/blob/main/jupyter-notebook/Logistic_Regression_Notebook.ipynb\n",
        "\n",
        "Banana Quality Dataset. Retrieved from https://www.kaggle.com/datasets/mrmars1010/banana-quality-dataset\n",
        "\n",
        "Scikit Learn: train_test_split. Retrieved from https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n"
      ],
      "metadata": {
        "id": "UuAIRSXAoce0"
      }
    }
  ]
}